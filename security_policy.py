#!/usr/bin/env python3
"""
VERÄ° GÃœVENLÄ°ÄÄ° VE SAKLAMA POLÄ°TÄ°KASI
==================================
GDPR/HIPAA baÄŸÄ±msÄ±z kurum iÃ§i veri gÃ¼venliÄŸi ve saklama sÃ¼reÃ§leri.
"""

import os
import json
import hashlib
import shutil
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import logging
import zipfile
import tempfile

logger = logging.getLogger(__name__)

class DataSecurityPolicy:
    """
    Veri gÃ¼venliÄŸi ve saklama politikalarÄ±nÄ± yÃ¶netir.
    Kurum iÃ§i sÃ¼reÃ§ler iÃ§in tasarlanmÄ±ÅŸtÄ±r.
    """
    
    # SAKLAMA POLÄ°TÄ°KALARI
    RETENTION_POLICIES = {
        "patient_videos": {
            "retention_period_days": 2555,  # 7 yÄ±l
            "encryption_required": True,
            "backup_required": True,
            "access_level": "restricted",
            "description": "Hasta video kayÄ±tlarÄ± - 7 yÄ±l saklama zorunlu"
        },
        "analysis_results": {
            "retention_period_days": 3650,  # 10 yÄ±l
            "encryption_required": True,
            "backup_required": True,
            "access_level": "controlled",
            "description": "Analiz sonuÃ§larÄ± ve raporlar - 10 yÄ±l saklama"
        },
        "audit_logs": {
            "retention_period_days": 2190,  # 6 yÄ±l
            "encryption_required": False,
            "backup_required": True,
            "access_level": "admin_only",
            "description": "Sistem eriÅŸim loglarÄ± - 6 yÄ±l saklama"
        },
        "user_sessions": {
            "retention_period_days": 90,    # 3 ay
            "encryption_required": False,
            "backup_required": False,
            "access_level": "system",
            "description": "KullanÄ±cÄ± oturum kayÄ±tlarÄ± - 3 ay saklama"
        },
        "temporary_files": {
            "retention_period_days": 7,     # 1 hafta
            "encryption_required": False,
            "backup_required": False,
            "access_level": "system",
            "description": "GeÃ§ici dosyalar - 1 hafta saklama"
        }
    }
    
    # ERÄ°ÅÄ°M SEVÄ°YELERÄ°
    ACCESS_LEVELS = {
        "public": {
            "description": "Herkese aÃ§Ä±k",
            "required_roles": [],
            "audit_required": False
        },
        "internal": {
            "description": "Kurum iÃ§i",
            "required_roles": ["user", "doctor", "admin"],
            "audit_required": True
        },
        "controlled": {
            "description": "KontrollÃ¼ eriÅŸim",
            "required_roles": ["doctor", "admin"],
            "audit_required": True
        },
        "restricted": {
            "description": "KÄ±sÄ±tlÄ± eriÅŸim",
            "required_roles": ["admin"],
            "audit_required": True
        },
        "admin_only": {
            "description": "Sadece yÃ¶netici",
            "required_roles": ["admin"],
            "audit_required": True
        },
        "system": {
            "description": "Sistem seviyesi",
            "required_roles": ["system"],
            "audit_required": False
        }
    }
    
    def __init__(self, base_storage_path: str = "secure_storage"):
        self.base_path = base_storage_path
        self.policies_file = os.path.join(base_storage_path, "security_policies.json")
        self.audit_log = os.path.join(base_storage_path, "security_audit.log")
        
        # GÃ¼venli dizinleri oluÅŸtur
        self._initialize_secure_storage()
        
        # Politika dosyasÄ±nÄ± yÃ¼kle/oluÅŸtur
        self._load_or_create_policies()
    
    def _initialize_secure_storage(self):
        """GÃ¼venli depolama dizinlerini baÅŸlatÄ±r."""
        try:
            # Ana dizinler
            directories = [
                self.base_path,
                os.path.join(self.base_path, "patient_data"),
                os.path.join(self.base_path, "analysis_results"),
                os.path.join(self.base_path, "audit_logs"),
                os.path.join(self.base_path, "backups"),
                os.path.join(self.base_path, "temp"),
                os.path.join(self.base_path, "quarantine")
            ]
            
            for directory in directories:
                if not os.path.exists(directory):
                    os.makedirs(directory, mode=0o750)  # KÄ±sÄ±tlÄ± izinler
                    logger.info(f"GÃ¼venli dizin oluÅŸturuldu: {directory}")
            
            # .gitignore oluÅŸtur (versiyon kontrolÃ¼nden hariÃ§ tut)
            gitignore_path = os.path.join(self.base_path, ".gitignore")
            if not os.path.exists(gitignore_path):
                with open(gitignore_path, 'w') as f:
                    f.write("# GÃ¼venli veri depolama - versiyon kontrolÃ¼ne dahil edilmez\n")
                    f.write("*\n")
                    f.write("!.gitignore\n")
                    f.write("!README_SECURITY.md\n")
            
        except Exception as e:
            logger.error(f"GÃ¼venli depolama baÅŸlatma hatasÄ±: {e}")
    
    def _load_or_create_policies(self):
        """GÃ¼venlik politikalarÄ±nÄ± yÃ¼kler veya oluÅŸturur."""
        try:
            if os.path.exists(self.policies_file):
                with open(self.policies_file, 'r', encoding='utf-8') as f:
                    self.active_policies = json.load(f)
                logger.info("GÃ¼venlik politikalarÄ± yÃ¼klendi")
            else:
                # VarsayÄ±lan politikalarÄ± oluÅŸtur
                self.active_policies = {
                    "version": "1.0",
                    "created_date": datetime.now().isoformat(),
                    "last_updated": datetime.now().isoformat(),
                    "retention_policies": self.RETENTION_POLICIES,
                    "access_levels": self.ACCESS_LEVELS,
                    "encryption_settings": {
                        "algorithm": "AES-256-CBC",
                        "key_rotation_days": 90,
                        "backup_encryption": True
                    },
                    "compliance_settings": {
                        "audit_all_access": True,
                        "log_retention_years": 6,
                        "data_anonymization": True,
                        "breach_notification_hours": 24
                    }
                }
                
                self._save_policies()
                logger.info("VarsayÄ±lan gÃ¼venlik politikalarÄ± oluÅŸturuldu")
                
        except Exception as e:
            logger.error(f"Politika yÃ¼kleme hatasÄ±: {e}")
            self.active_policies = {}
    
    def _save_policies(self):
        """GÃ¼venlik politikalarÄ±nÄ± kaydeder."""
        try:
            self.active_policies["last_updated"] = datetime.now().isoformat()
            
            with open(self.policies_file, 'w', encoding='utf-8') as f:
                json.dump(self.active_policies, f, indent=2, ensure_ascii=False)
            
            # Dosya izinlerini kÄ±sÄ±tla
            os.chmod(self.policies_file, 0o640)
            
        except Exception as e:
            logger.error(f"Politika kaydetme hatasÄ±: {e}")
    
    def store_patient_video(self, video_path: str, patient_id: str, 
                           metadata: Dict[str, Any] = None) -> str:
        """
        Hasta videosunu gÃ¼venli ÅŸekilde depolar.
        
        Args:
            video_path: Orijinal video dosya yolu
            patient_id: Hasta kimliÄŸi (anonimleÅŸtirilecek)
            metadata: Video metadata'sÄ±
            
        Returns:
            str: GÃ¼venli depolama ID'si
        """
        try:
            # Benzersiz depolama ID'si oluÅŸtur
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            storage_id = hashlib.sha256(f"{patient_id}_{timestamp}".encode()).hexdigest()[:16]
            
            # GÃ¼venli dosya yolu
            secure_filename = f"video_{storage_id}.encrypted"
            secure_path = os.path.join(self.base_path, "patient_data", secure_filename)
            
            # Video dosyasÄ±nÄ± ÅŸifrele ve depola
            encrypted_data = self._encrypt_file(video_path)
            
            with open(secure_path, 'wb') as f:
                f.write(encrypted_data)
            
            # Metadata kaydet
            metadata_info = {
                "storage_id": storage_id,
                "original_filename": os.path.basename(video_path),
                "patient_id_hash": hashlib.sha256(patient_id.encode()).hexdigest()[:16],
                "stored_date": datetime.now().isoformat(),
                "expiry_date": (datetime.now() + timedelta(days=self.RETENTION_POLICIES["patient_videos"]["retention_period_days"])).isoformat(),
                "file_size": os.path.getsize(video_path),
                "encryption": "AES-256-CBC",
                "access_level": "restricted",
                "metadata": metadata or {}
            }
            
            metadata_path = os.path.join(self.base_path, "patient_data", f"meta_{storage_id}.json")
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata_info, f, indent=2, ensure_ascii=False)
            
            # Dosya izinlerini ayarla
            os.chmod(secure_path, 0o600)  # Sadece sahip okuyabilir
            os.chmod(metadata_path, 0o640)
            
            # Audit log
            self._log_security_event("video_stored", {
                "storage_id": storage_id,
                "patient_id_hash": metadata_info["patient_id_hash"],
                "file_size": metadata_info["file_size"]
            })
            
            logger.info(f"Video gÃ¼venli ÅŸekilde depolandÄ±: {storage_id}")
            return storage_id
            
        except Exception as e:
            logger.error(f"Video depolama hatasÄ±: {e}")
            return ""
    
    def retrieve_patient_video(self, storage_id: str, requesting_user: str, 
                              access_reason: str) -> Optional[str]:
        """
        Hasta videosunu gÃ¼venli ÅŸekilde getirir.
        
        Args:
            storage_id: Depolama ID'si
            requesting_user: Ä°steÄŸi yapan kullanÄ±cÄ±
            access_reason: EriÅŸim nedeni
            
        Returns:
            str: GeÃ§ici dosya yolu (None ise eriÅŸim reddedildi)
        """
        try:
            # Metadata kontrol et
            metadata_path = os.path.join(self.base_path, "patient_data", f"meta_{storage_id}.json")
            
            if not os.path.exists(metadata_path):
                logger.warning(f"Video bulunamadÄ±: {storage_id}")
                return None
            
            with open(metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            # SÃ¼re kontrolÃ¼
            expiry_date = datetime.fromisoformat(metadata["expiry_date"])
            if datetime.now() > expiry_date:
                logger.warning(f"Video sÃ¼resi dolmuÅŸ: {storage_id}")
                return None
            
            # EriÅŸim kontrolÃ¼ (basit uygulama)
            if not self._check_access_permission(requesting_user, metadata["access_level"]):
                logger.warning(f"EriÅŸim reddedildi - User: {requesting_user}, Video: {storage_id}")
                self._log_security_event("access_denied", {
                    "storage_id": storage_id,
                    "user": requesting_user,
                    "reason": access_reason
                })
                return None
            
            # Åifreli dosyayÄ± oku
            secure_path = os.path.join(self.base_path, "patient_data", f"video_{storage_id}.encrypted")
            
            if not os.path.exists(secure_path):
                logger.error(f"Åifreli video dosyasÄ± bulunamadÄ±: {storage_id}")
                return None
            
            # DosyayÄ± Ã§Ã¶z ve geÃ§ici dizine kaydet
            with open(secure_path, 'rb') as f:
                encrypted_data = f.read()
            
            decrypted_data = self._decrypt_file_data(encrypted_data)
            
            # GeÃ§ici dosya oluÅŸtur
            temp_dir = os.path.join(self.base_path, "temp")
            temp_filename = f"temp_{storage_id}_{datetime.now().strftime('%H%M%S')}.mp4"
            temp_path = os.path.join(temp_dir, temp_filename)
            
            with open(temp_path, 'wb') as f:
                f.write(decrypted_data)
            
            # GeÃ§ici dosya izinleri
            os.chmod(temp_path, 0o600)
            
            # Audit log
            self._log_security_event("video_accessed", {
                "storage_id": storage_id,
                "user": requesting_user,
                "reason": access_reason,
                "temp_file": temp_filename
            })
            
            logger.info(f"Video eriÅŸimi saÄŸlandÄ±: {storage_id} -> {requesting_user}")
            return temp_path
            
        except Exception as e:
            logger.error(f"Video getirme hatasÄ±: {e}")
            return None
    
    def store_analysis_result(self, analysis_data: Dict[str, Any], 
                            patient_id: str, analysis_type: str = "nystagmus") -> str:
        """Analiz sonucunu gÃ¼venli ÅŸekilde depolar."""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            result_id = hashlib.sha256(f"{patient_id}_{analysis_type}_{timestamp}".encode()).hexdigest()[:16]
            
            # SonuÃ§ verisi hazÄ±rla
            result_data = {
                "result_id": result_id,
                "analysis_type": analysis_type,
                "patient_id_hash": hashlib.sha256(patient_id.encode()).hexdigest()[:16],
                "analysis_date": datetime.now().isoformat(),
                "expiry_date": (datetime.now() + timedelta(days=self.RETENTION_POLICIES["analysis_results"]["retention_period_days"])).isoformat(),
                "data": analysis_data,
                "system_info": {
                    "version": "1.0",
                    "analyzer": "NystagmusDetector"
                }
            }
            
            # Dosya yolu
            result_filename = f"analysis_{result_id}.json"
            result_path = os.path.join(self.base_path, "analysis_results", result_filename)
            
            # Åifreli kaydet (eÄŸer gerekiyorsa)
            if self.RETENTION_POLICIES["analysis_results"]["encryption_required"]:
                encrypted_data = self._encrypt_data(json.dumps(result_data, ensure_ascii=False))
                result_filename = f"analysis_{result_id}.encrypted"
                result_path = os.path.join(self.base_path, "analysis_results", result_filename)
                
                with open(result_path, 'wb') as f:
                    f.write(encrypted_data)
            else:
                with open(result_path, 'w', encoding='utf-8') as f:
                    json.dump(result_data, f, indent=2, ensure_ascii=False)
            
            # Dosya izinleri
            os.chmod(result_path, 0o640)
            
            # Audit log
            self._log_security_event("analysis_stored", {
                "result_id": result_id,
                "patient_id_hash": result_data["patient_id_hash"],
                "analysis_type": analysis_type
            })
            
            logger.info(f"Analiz sonucu depolandÄ±: {result_id}")
            return result_id
            
        except Exception as e:
            logger.error(f"Analiz sonucu depolama hatasÄ±: {e}")
            return ""
    
    def cleanup_expired_data(self) -> Dict[str, int]:
        """SÃ¼resi dolmuÅŸ verileri temizler."""
        try:
            cleanup_stats = {
                "patient_videos": 0,
                "analysis_results": 0,
                "audit_logs": 0,
                "temp_files": 0
            }
            
            current_time = datetime.now()
            
            # Hasta videolarÄ± temizle
            patient_data_dir = os.path.join(self.base_path, "patient_data")
            for filename in os.listdir(patient_data_dir):
                if filename.startswith("meta_") and filename.endswith(".json"):
                    meta_path = os.path.join(patient_data_dir, filename)
                    
                    try:
                        with open(meta_path, 'r', encoding='utf-8') as f:
                            metadata = json.load(f)
                        
                        expiry_date = datetime.fromisoformat(metadata["expiry_date"])
                        
                        if current_time > expiry_date:
                            storage_id = metadata["storage_id"]
                            
                            # Video dosyasÄ±nÄ± sil
                            video_path = os.path.join(patient_data_dir, f"video_{storage_id}.encrypted")
                            if os.path.exists(video_path):
                                os.remove(video_path)
                            
                            # Metadata dosyasÄ±nÄ± sil
                            os.remove(meta_path)
                            
                            cleanup_stats["patient_videos"] += 1
                            
                            self._log_security_event("expired_data_cleaned", {
                                "type": "patient_video",
                                "storage_id": storage_id
                            })
                            
                    except Exception as e:
                        logger.error(f"Video temizleme hatasÄ± {filename}: {e}")
            
            # GeÃ§ici dosyalarÄ± temizle (7 gÃ¼nden eski)
            temp_dir = os.path.join(self.base_path, "temp")
            cutoff_time = current_time - timedelta(days=7)
            
            for filename in os.listdir(temp_dir):
                file_path = os.path.join(temp_dir, filename)
                file_mtime = datetime.fromtimestamp(os.path.getmtime(file_path))
                
                if file_mtime < cutoff_time:
                    os.remove(file_path)
                    cleanup_stats["temp_files"] += 1
            
            # Audit log
            self._log_security_event("cleanup_completed", cleanup_stats)
            
            logger.info(f"Veri temizleme tamamlandÄ±: {cleanup_stats}")
            return cleanup_stats
            
        except Exception as e:
            logger.error(f"Veri temizleme hatasÄ±: {e}")
            return {}
    
    def create_backup(self, backup_type: str = "full") -> str:
        """GÃ¼venli yedekleme oluÅŸturur."""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_filename = f"backup_{backup_type}_{timestamp}.zip"
            backup_path = os.path.join(self.base_path, "backups", backup_filename)
            
            # ZIP dosyasÄ± oluÅŸtur
            with zipfile.ZipFile(backup_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                if backup_type == "full":
                    # TÃ¼m kritik dizinleri yedekle
                    dirs_to_backup = ["patient_data", "analysis_results", "audit_logs"]
                elif backup_type == "analysis_only":
                    dirs_to_backup = ["analysis_results"]
                elif backup_type == "audit_only":
                    dirs_to_backup = ["audit_logs"]
                else:
                    dirs_to_backup = ["patient_data", "analysis_results"]
                
                for dir_name in dirs_to_backup:
                    dir_path = os.path.join(self.base_path, dir_name)
                    if os.path.exists(dir_path):
                        for root, _, files in os.walk(dir_path):
                            for file in files:
                                file_path = os.path.join(root, file)
                                arcname = os.path.relpath(file_path, self.base_path)
                                zipf.write(file_path, arcname)
            
            # Yedekleme dosyasÄ± izinleri
            os.chmod(backup_path, 0o600)
            
            # Audit log
            self._log_security_event("backup_created", {
                "backup_type": backup_type,
                "backup_file": backup_filename,
                "file_size": os.path.getsize(backup_path)
            })
            
            logger.info(f"Yedekleme oluÅŸturuldu: {backup_filename}")
            return backup_path
            
        except Exception as e:
            logger.error(f"Yedekleme hatasÄ±: {e}")
            return ""
    
    def _encrypt_file(self, file_path: str) -> bytes:
        """DosyayÄ± ÅŸifreler."""
        try:
            from cryptography.fernet import Fernet
            
            # Basit anahtar (Ã¼retimde key management sistemi kullanÄ±n)
            key = b'your-secret-key-here-32-characters!'
            cipher_suite = Fernet(Fernet.generate_key())
            
            with open(file_path, 'rb') as f:
                file_data = f.read()
            
            encrypted_data = cipher_suite.encrypt(file_data)
            return encrypted_data
            
        except Exception as e:
            logger.error(f"Dosya ÅŸifreleme hatasÄ±: {e}")
            return b""
    
    def _encrypt_data(self, data: str) -> bytes:
        """String veriyi ÅŸifreler."""
        try:
            from cryptography.fernet import Fernet
            
            cipher_suite = Fernet(Fernet.generate_key())
            encrypted_data = cipher_suite.encrypt(data.encode('utf-8'))
            return encrypted_data
            
        except Exception as e:
            logger.error(f"Veri ÅŸifreleme hatasÄ±: {e}")
            return b""
    
    def _decrypt_file_data(self, encrypted_data: bytes) -> bytes:
        """Åifreli veriyi Ã§Ã¶zer."""
        try:
            from cryptography.fernet import Fernet
            
            # Not: GerÃ§ek uygulamada anahtar yÃ¶netimi gerekli
            cipher_suite = Fernet(Fernet.generate_key())
            decrypted_data = cipher_suite.decrypt(encrypted_data)
            return decrypted_data
            
        except Exception as e:
            logger.error(f"Veri Ã§Ã¶zme hatasÄ±: {e}")
            return b""
    
    def _check_access_permission(self, user: str, required_level: str) -> bool:
        """EriÅŸim iznini kontrol eder."""
        # Basit uygulama - gerÃ§ek sistemde role-based access control
        if required_level == "public":
            return True
        elif required_level == "system":
            return user == "system"
        elif required_level in ["internal", "controlled", "restricted", "admin_only"]:
            # Demo iÃ§in admin her ÅŸeye eriÅŸebilir
            return user in ["admin", "doctor"] or "admin" in user.lower()
        
        return False
    
    def _log_security_event(self, event_type: str, details: Dict[str, Any]):
        """GÃ¼venlik olayÄ±nÄ± loglar."""
        try:
            log_entry = {
                "timestamp": datetime.now().isoformat(),
                "event_type": event_type,
                "details": details,
                "system": "DataSecurityPolicy"
            }
            
            with open(self.audit_log, 'a', encoding='utf-8') as f:
                f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
                
        except Exception as e:
            logger.error(f"GÃ¼venlik log hatasÄ±: {e}")
    
    def generate_security_report(self) -> Dict[str, Any]:
        """GÃ¼venlik durumu raporu oluÅŸturur."""
        try:
            report = {
                "report_date": datetime.now().isoformat(),
                "storage_statistics": self._get_storage_statistics(),
                "retention_compliance": self._check_retention_compliance(),
                "access_summary": self._get_access_summary(),
                "backup_status": self._get_backup_status(),
                "security_recommendations": self._generate_security_recommendations()
            }
            
            return report
            
        except Exception as e:
            logger.error(f"GÃ¼venlik raporu hatasÄ±: {e}")
            return {"error": str(e)}
    
    def _get_storage_statistics(self) -> Dict[str, Any]:
        """Depolama istatistiklerini getirir."""
        stats = {}
        
        for data_type in ["patient_data", "analysis_results", "audit_logs", "backups"]:
            dir_path = os.path.join(self.base_path, data_type)
            if os.path.exists(dir_path):
                file_count = len([f for f in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, f))])
                total_size = sum(os.path.getsize(os.path.join(dir_path, f)) 
                               for f in os.listdir(dir_path) 
                               if os.path.isfile(os.path.join(dir_path, f)))
                
                stats[data_type] = {
                    "file_count": file_count,
                    "total_size_mb": round(total_size / 1024 / 1024, 2)
                }
        
        return stats
    
    def _check_retention_compliance(self) -> List[str]:
        """Saklama politikasÄ± uyumluluÄŸunu kontrol eder."""
        compliance_issues = []
        
        # Bu metodun tam implementasyonu storage statistics ve policy kontrolÃ¼ gerektirir
        # Demo iÃ§in basit kontrol
        
        return compliance_issues
    
    def _get_access_summary(self) -> Dict[str, int]:
        """EriÅŸim Ã¶zetini getirir.""" 
        # Audit log'dan eriÅŸim istatistiklerini Ã§Ä±kar
        summary = {
            "video_access_count": 0,
            "analysis_access_count": 0,
            "denied_access_count": 0
        }
        
        return summary
    
    def _get_backup_status(self) -> Dict[str, Any]:
        """Yedekleme durumunu getirir."""
        backup_dir = os.path.join(self.base_path, "backups")
        
        if not os.path.exists(backup_dir):
            return {"status": "no_backups", "last_backup": None}
        
        backup_files = [f for f in os.listdir(backup_dir) if f.startswith("backup_")]
        
        if not backup_files:
            return {"status": "no_backups", "last_backup": None}
        
        # En son yedeklemeyi bul
        latest_backup = max(backup_files, key=lambda x: os.path.getctime(os.path.join(backup_dir, x)))
        latest_backup_time = datetime.fromtimestamp(os.path.getctime(os.path.join(backup_dir, latest_backup)))
        
        return {
            "status": "active",
            "backup_count": len(backup_files),
            "last_backup": latest_backup_time.isoformat(),
            "latest_backup_file": latest_backup
        }
    
    def _generate_security_recommendations(self) -> List[str]:
        """GÃ¼venlik Ã¶nerileri oluÅŸturur."""
        recommendations = [
            "ğŸ” DÃ¼zenli anahtar rotasyonu yapÄ±n (90 gÃ¼nde bir)",
            "ğŸ“Š HaftalÄ±k gÃ¼venlik raporlarÄ± oluÅŸturun",
            "ğŸ—„ï¸ AylÄ±k yedekleme doÄŸrulamasÄ± yapÄ±n",
            "ğŸ‘¥ KullanÄ±cÄ± eriÅŸim izinlerini gÃ¶zden geÃ§irin",
            "ğŸ§¹ DÃ¼zenli veri temizleme iÅŸlemi Ã§alÄ±ÅŸtÄ±rÄ±n"
        ]
        
        return recommendations

# Factory function
def create_security_policy() -> DataSecurityPolicy:
    """GÃ¼venlik politikasÄ± yÃ¶neticisi oluÅŸtur."""
    return DataSecurityPolicy()

if __name__ == "__main__":
    # Test
    policy = DataSecurityPolicy()
    print("ğŸ”’ Veri gÃ¼venliÄŸi politikasÄ± test edildi")
    print(f"Saklama politikalarÄ±: {len(policy.RETENTION_POLICIES)}")
    print(f"EriÅŸim seviyeleri: {len(policy.ACCESS_LEVELS)}")
    
    # GÃ¼venlik raporu oluÅŸtur
    report = policy.generate_security_report()
    print(f"\nğŸ“Š GÃ¼venlik raporu oluÅŸturuldu")
    print(f"Depolama dizinleri: {list(report.get('storage_statistics', {}).keys())}") 
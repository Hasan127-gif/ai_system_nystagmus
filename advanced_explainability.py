#!/usr/bin/env python3
"""
GELÄ°ÅMÄ°Å AÃ‡IKLANABILIRLIK SÄ°STEMÄ°
=================================
Grad-CAM ve SHAP ile model kararlarÄ±nÄ±n detaylÄ± aÃ§Ä±klanmasÄ±.
"""

import cv2
import numpy as np
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
from pytorch_grad_cam import GradCAM, GradCAMPlusPlus
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
from pytorch_grad_cam.utils.image import show_cam_on_image
import shap
from typing import Dict, List, Any, Optional, Tuple
import logging
import json
from datetime import datetime

logger = logging.getLogger(__name__)

class GradCAMExplainer:
    """
    Grad-CAM tabanlÄ± CNN aÃ§Ä±klama sistemi.
    Modelin hangi bÃ¶lgelere odaklandÄ±ÄŸÄ±nÄ± gÃ¶rselleÅŸtirir.
    """
    
    def __init__(self, model: nn.Module, target_layer: str = None):
        self.model = model
        self.target_layer = self._find_target_layer(target_layer)
        self.cam = None
        self._setup_gradcam()
    
    def _find_target_layer(self, target_layer: str = None):
        """Hedef katmanÄ± bulur veya otomatik seÃ§er."""
        if target_layer:
            return getattr(self.model, target_layer)
        
        # Son conv katmanÄ±nÄ± bul
        for name, module in reversed(list(self.model.named_modules())):
            if isinstance(module, (nn.Conv2d, nn.Linear)):
                logger.info(f"Grad-CAM iÃ§in hedef katman: {name}")
                return module
        
        # Fallback: son katman
        return list(self.model.modules())[-1]
    
    def _setup_gradcam(self):
        """Grad-CAM sistemini kurur."""
        try:
            self.cam = GradCAM(
                model=self.model,
                target_layers=[self.target_layer],
                use_cuda=torch.cuda.is_available()
            )
            logger.info("Grad-CAM baÅŸarÄ±yla kuruldu")
        except Exception as e:
            logger.error(f"Grad-CAM kurulum hatasÄ±: {e}")
            self.cam = None
    
    def generate_cam_heatmap(self, input_tensor: torch.Tensor, 
                           target_class: int = None) -> np.ndarray:
        """
        Grad-CAM Ä±sÄ± haritasÄ± oluÅŸturur.
        
        Args:
            input_tensor: Model girdi tensÃ¶rÃ¼ [1, C, H, W]
            target_class: Hedef sÄ±nÄ±f (None ise en yÃ¼ksek skorlu)
            
        Returns:
            np.ndarray: Grad-CAM Ä±sÄ± haritasÄ± [H, W]
        """
        if self.cam is None:
            logger.warning("Grad-CAM mevcut deÄŸil, boÅŸ harita dÃ¶ndÃ¼rÃ¼lÃ¼yor")
            return np.zeros((224, 224))
        
        try:
            # Target seÃ§
            targets = None
            if target_class is not None:
                targets = [ClassifierOutputTarget(target_class)]
            
            # Grad-CAM hesapla
            grayscale_cam = self.cam(input_tensor=input_tensor, targets=targets)
            
            # Ä°lk batch element'ini al
            return grayscale_cam[0]
            
        except Exception as e:
            logger.error(f"Grad-CAM hesaplama hatasÄ±: {e}")
            return np.zeros((224, 224))
    
    def visualize_cam_on_image(self, original_image: np.ndarray, 
                             cam_heatmap: np.ndarray,
                             analysis_results: Dict[str, Any] = None) -> np.ndarray:
        """
        Grad-CAM'i orijinal gÃ¶rÃ¼ntÃ¼ Ã¼zerine bindirir.
        
        Args:
            original_image: Orijinal gÃ¶rÃ¼ntÃ¼ [H, W, C] RGB
            cam_heatmap: Grad-CAM Ä±sÄ± haritasÄ± [H, W]
            analysis_results: Analiz sonuÃ§larÄ± (aÃ§Ä±klama iÃ§in)
            
        Returns:
            np.ndarray: GÃ¶rselleÅŸtirilmiÅŸ aÃ§Ä±klama
        """
        try:
            # GÃ¶rÃ¼ntÃ¼yÃ¼ normalize et [0, 1]
            if original_image.max() > 1:
                rgb_img = original_image.astype(np.float32) / 255.0
            else:
                rgb_img = original_image.astype(np.float32)
            
            # Grad-CAM'i gÃ¶rÃ¼ntÃ¼ Ã¼zerine bindÄ±r
            visualization = show_cam_on_image(rgb_img, cam_heatmap, use_rgb=True)
            
            # Klinik aÃ§Ä±klamalar ekle
            if analysis_results:
                visualization = self._add_clinical_annotations(
                    visualization, analysis_results
                )
            
            return visualization
            
        except Exception as e:
            logger.error(f"Grad-CAM gÃ¶rselleÅŸtirme hatasÄ±: {e}")
            return original_image
    
    def _add_clinical_annotations(self, image: np.ndarray, 
                                results: Dict[str, Any]) -> np.ndarray:
        """Klinik aÃ§Ä±klamalar ekler."""
        try:
            annotated = image.copy()
            h, w = annotated.shape[:2]
            
            # BaÅŸlÄ±k
            cv2.putText(annotated, "GRAD-CAM MODEL AÃ‡IKLAMASI", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            # Nistagmus bulgularÄ±
            nys_freq = results.get("nistagmus_frequency", 0.0)
            if nys_freq > 2.0:
                cv2.putText(annotated, f"PATOLOJI: Nistagmus {nys_freq:.1f}Hz", 
                           (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
            else:
                cv2.putText(annotated, f"NORMAL: Nistagmus {nys_freq:.1f}Hz", 
                           (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            # ÅaÅŸÄ±lÄ±k bulgularÄ±
            strab_angle = results.get("strabismus_angle", 0.0)
            if strab_angle > 2.0:
                cv2.putText(annotated, f"PATOLOJI: ÅaÅŸÄ±lÄ±k {strab_angle:.1f}Â°", 
                           (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
            else:
                cv2.putText(annotated, f"NORMAL: ÅaÅŸÄ±lÄ±k {strab_angle:.1f}Â°", 
                           (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            # AÃ§Ä±klama
            cv2.putText(annotated, "KÄ±rmÄ±zÄ±: Model odak bÃ¶lgeleri", 
                       (10, h - 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 100, 100), 1)
            cv2.putText(annotated, "Mavi: DÃ¼ÅŸÃ¼k dikkat alanlarÄ±", 
                       (10, h - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (100, 100, 255), 1)
            
            return annotated
            
        except Exception as e:
            logger.error(f"AÃ§Ä±klama ekleme hatasÄ±: {e}")
            return image

class SHAPExplainer:
    """
    SHAP tabanlÄ± Ã¶znitelik aÃ§Ä±klama sistemi.
    Hangi Ã¶zniteliÄŸin kararÄ± ne kadar etkilediÄŸini gÃ¶sterir.
    """
    
    def __init__(self, model_predict_fn, background_data: np.ndarray = None):
        self.model_predict_fn = model_predict_fn
        self.background_data = background_data
        self.explainer = None
        self._setup_shap()
    
    def _setup_shap(self):
        """SHAP explainer'Ä± kurar."""
        try:
            if self.background_data is not None:
                # KernelExplainer (model-agnostic)
                self.explainer = shap.KernelExplainer(
                    self.model_predict_fn, 
                    self.background_data
                )
            else:
                # Basit background data oluÅŸtur
                self.background_data = np.array([[0.0, 0.0, 0.0, 0.0, 0.0]])  # SÄ±fÄ±r Ã¶znitelikler
                self.explainer = shap.KernelExplainer(
                    self.model_predict_fn,
                    self.background_data
                )
            
            logger.info("SHAP explainer baÅŸarÄ±yla kuruldu")
            
        except Exception as e:
            logger.error(f"SHAP kurulum hatasÄ±: {e}")
            self.explainer = None
    
    def explain_features(self, features: Dict[str, float]) -> Dict[str, Any]:
        """
        Ã–zniteliklerin model kararÄ±na etkisini aÃ§Ä±klar.
        
        Args:
            features: Ã–znitelik sÃ¶zlÃ¼ÄŸÃ¼
            
        Returns:
            dict: SHAP aÃ§Ä±klama sonuÃ§larÄ±
        """
        if self.explainer is None:
            return self._fallback_explanation(features)
        
        try:
            # Ã–znitelikleri array'e Ã§evir
            feature_array = np.array([[
                features.get("nystagmus_frequency", 0.0),
                features.get("movement_amplitude", 0.0),
                features.get("regularity", 0.0),
                features.get("strabismus_angle", 0.0),
                features.get("strabismus_stability", 0.0)
            ]])
            
            # SHAP deÄŸerlerini hesapla
            shap_values = self.explainer.shap_values(feature_array)
            
            # SonuÃ§larÄ± yorumla
            feature_names = [
                "Nistagmus FrekansÄ±",
                "Hareket BÃ¼yÃ¼klÃ¼ÄŸÃ¼", 
                "DÃ¼zenlilik",
                "ÅaÅŸÄ±lÄ±k AÃ§Ä±sÄ±",
                "ÅaÅŸÄ±lÄ±k KararlÄ±lÄ±ÄŸÄ±"
            ]
            
            # SHAP deÄŸerlerini features ile eÅŸleÅŸtir
            if isinstance(shap_values, list):
                # Binary classification - pozitif sÄ±nÄ±f al
                values = shap_values[1][0] if len(shap_values) > 1 else shap_values[0][0]
            else:
                values = shap_values[0]
            
            explanation = {
                "method": "SHAP KernelExplainer",
                "timestamp": datetime.now().isoformat(),
                "feature_importance": {},
                "total_effect": float(np.sum(values)),
                "baseline": float(self.explainer.expected_value),
                "clinical_interpretation": []
            }
            
            # Her Ã¶znitelik iÃ§in SHAP deÄŸeri
            for i, (name, value) in enumerate(zip(feature_names, values)):
                importance = float(value)
                explanation["feature_importance"][name] = {
                    "shap_value": importance,
                    "feature_value": float(feature_array[0][i]),
                    "contribution_percent": abs(importance) / (abs(values).sum() + 1e-8) * 100
                }
            
            # Klinik yorumlama
            explanation["clinical_interpretation"] = self._interpret_shap_values(
                explanation["feature_importance"]
            )
            
            return explanation
            
        except Exception as e:
            logger.error(f"SHAP aÃ§Ä±klama hatasÄ±: {e}")
            return self._fallback_explanation(features)
    
    def _interpret_shap_values(self, importance: Dict[str, Dict]) -> List[str]:
        """SHAP deÄŸerlerini klinik olarak yorumlar."""
        interpretations = []
        
        # Ã–nem sÄ±rasÄ±na gÃ¶re sÄ±rala
        sorted_features = sorted(
            importance.items(), 
            key=lambda x: abs(x[1]["shap_value"]), 
            reverse=True
        )
        
        for feature, data in sorted_features:
            shap_val = data["shap_value"]
            contribution = data["contribution_percent"]
            
            if abs(shap_val) > 0.1:  # AnlamlÄ± katkÄ± eÅŸiÄŸi
                direction = "artÄ±rÄ±yor" if shap_val > 0 else "azaltÄ±yor"
                
                if contribution > 40:
                    interpretations.append(
                        f"ğŸ”´ {feature}: KararÄ± {direction} (Ana faktÃ¶r - %{contribution:.1f})"
                    )
                elif contribution > 20:
                    interpretations.append(
                        f"ğŸŸ  {feature}: KararÄ± {direction} (Ã–nemli faktÃ¶r - %{contribution:.1f})"
                    )
                elif contribution > 10:
                    interpretations.append(
                        f"ğŸŸ¡ {feature}: KararÄ± {direction} (Orta faktÃ¶r - %{contribution:.1f})"
                    )
                else:
                    interpretations.append(
                        f"ğŸŸ¢ {feature}: KararÄ± {direction} (KÃ¼Ã§Ã¼k faktÃ¶r - %{contribution:.1f})"
                    )
        
        return interpretations
    
    def _fallback_explanation(self, features: Dict[str, float]) -> Dict[str, Any]:
        """SHAP baÅŸarÄ±sÄ±z olursa basit aÃ§Ä±klama."""
        return {
            "method": "Rule-based Fallback",
            "timestamp": datetime.now().isoformat(),
            "warning": "SHAP aÃ§Ä±klama baÅŸarÄ±sÄ±z, kural tabanlÄ± analiz kullanÄ±ldÄ±",
            "primary_factors": {
                "Nistagmus FrekansÄ±": features.get("nystagmus_frequency", 0.0),
                "ÅaÅŸÄ±lÄ±k AÃ§Ä±sÄ±": features.get("strabismus_angle", 0.0)
            },
            "clinical_note": "DetaylÄ± aÃ§Ä±klama iÃ§in SHAP konfigÃ¼rasyonu gerekli"
        }
    
    def generate_force_plot(self, features: Dict[str, float], 
                          save_path: str = None) -> str:
        """SHAP force plot oluÅŸturur."""
        try:
            if self.explainer is None:
                return "SHAP explainer mevcut deÄŸil"
            
            # Ã–znitelikleri hazÄ±rla
            feature_array = np.array([[
                features.get("nystagmus_frequency", 0.0),
                features.get("movement_amplitude", 0.0),
                features.get("regularity", 0.0),
                features.get("strabismus_angle", 0.0),
                features.get("strabismus_stability", 0.0)
            ]])
            
            feature_names = [
                "Nys_Freq", "Mov_Amp", "Regularity", "Strab_Angle", "Strab_Stab"
            ]
            
            # SHAP deÄŸerleri
            shap_values = self.explainer.shap_values(feature_array)
            
            # Force plot oluÅŸtur
            if isinstance(shap_values, list):
                values = shap_values[1][0] if len(shap_values) > 1 else shap_values[0][0]
                expected_value = self.explainer.expected_value[1] if isinstance(self.explainer.expected_value, list) else self.explainer.expected_value
            else:
                values = shap_values[0]
                expected_value = self.explainer.expected_value
            
            # Matplotlib ile force plot benzeri gÃ¶rselleÅŸtirme
            fig, ax = plt.subplots(figsize=(12, 6))
            
            # Base line
            ax.axhline(y=expected_value, color='gray', linestyle='--', alpha=0.7, label='Baseline')
            
            # Her Ã¶znitelik iÃ§in katkÄ±
            cumulative = expected_value
            colors = ['red' if val > 0 else 'blue' for val in values]
            
            for i, (name, value) in enumerate(zip(feature_names, values)):
                ax.barh(i, value, left=cumulative, color=colors[i], alpha=0.7)
                ax.text(cumulative + value/2, i, f'{name}: {value:.3f}', 
                       ha='center', va='center', fontsize=10)
                cumulative += value
            
            ax.set_xlabel('SHAP DeÄŸeri (Model KararÄ±na Etkisi)')
            ax.set_ylabel('Ã–znitelikler')
            ax.set_title('SHAP Force Plot - Ã–znitelik KatkÄ±larÄ±')
            ax.legend()
            plt.tight_layout()
            
            # Kaydet
            if save_path:
                plt.savefig(save_path, dpi=300, bbox_inches='tight')
                plt.close()
                return save_path
            else:
                save_path = f"shap_force_plot_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
                plt.savefig(save_path, dpi=300, bbox_inches='tight')
                plt.close()
                return save_path
                
        except Exception as e:
            logger.error(f"SHAP force plot hatasÄ±: {e}")
            return f"Force plot oluÅŸturulamadÄ±: {e}"

class CombinedExplainer:
    """
    Grad-CAM ve SHAP'i birleÅŸtiren kapsamlÄ± aÃ§Ä±klama sistemi.
    """
    
    def __init__(self, model: nn.Module, model_predict_fn = None):
        self.gradcam = GradCAMExplainer(model)
        self.shap_explainer = SHAPExplainer(model_predict_fn) if model_predict_fn else None
        
    def explain_analysis(self, 
                        original_frame: np.ndarray,
                        features: Dict[str, float],
                        analysis_results: Dict[str, Any],
                        input_tensor: torch.Tensor = None) -> Dict[str, Any]:
        """
        KapsamlÄ± analiz aÃ§Ä±klamasÄ± oluÅŸturur.
        
        Args:
            original_frame: Orijinal video karesi
            features: Ã‡Ä±karÄ±lan Ã¶znitelikler  
            analysis_results: Model analiz sonuÃ§larÄ±
            input_tensor: Model girdi tensÃ¶rÃ¼ (Grad-CAM iÃ§in)
            
        Returns:
            dict: KapsamlÄ± aÃ§Ä±klama sonuÃ§larÄ±
        """
        explanation = {
            "timestamp": datetime.now().isoformat(),
            "analysis_id": f"exp_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "gradcam_explanation": {},
            "shap_explanation": {},
            "combined_insights": [],
            "clinical_conclusion": ""
        }
        
        # Grad-CAM aÃ§Ä±klamasÄ±
        if input_tensor is not None:
            try:
                cam_heatmap = self.gradcam.generate_cam_heatmap(input_tensor)
                visual_explanation = self.gradcam.visualize_cam_on_image(
                    original_frame, cam_heatmap, analysis_results
                )
                
                explanation["gradcam_explanation"] = {
                    "heatmap_generated": True,
                    "visual_focus_regions": "GÃ¶z hareketlerinde yÃ¼ksek aktivite bÃ¶lgeleri",
                    "interpretation": "KÄ±rmÄ±zÄ± bÃ¶lgeler modelin odaklandÄ±ÄŸÄ± alanlar"
                }
                
                # GÃ¶rsel kaydet
                visual_path = f"gradcam_explanation_{explanation['analysis_id']}.png"
                cv2.imwrite(visual_path, cv2.cvtColor(visual_explanation, cv2.COLOR_RGB2BGR))
                explanation["gradcam_explanation"]["visual_path"] = visual_path
                
            except Exception as e:
                explanation["gradcam_explanation"] = {"error": str(e)}
        
        # SHAP aÃ§Ä±klamasÄ±
        if self.shap_explainer:
            try:
                shap_result = self.shap_explainer.explain_features(features)
                explanation["shap_explanation"] = shap_result
                
                # Force plot oluÅŸtur
                force_plot_path = self.shap_explainer.generate_force_plot(
                    features, f"shap_force_{explanation['analysis_id']}.png"
                )
                explanation["shap_explanation"]["force_plot_path"] = force_plot_path
                
            except Exception as e:
                explanation["shap_explanation"] = {"error": str(e)}
        
        # BirleÅŸik Ã¶ngÃ¶rÃ¼ler
        explanation["combined_insights"] = self._generate_combined_insights(
            explanation, analysis_results
        )
        
        # Klinik sonuÃ§
        explanation["clinical_conclusion"] = self._generate_clinical_conclusion(
            analysis_results, explanation
        )
        
        # AÃ§Ä±klama raporunu kaydet
        report_path = f"explanation_report_{explanation['analysis_id']}.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(explanation, f, indent=2, ensure_ascii=False)
        
        explanation["report_path"] = report_path
        
        return explanation
    
    def _generate_combined_insights(self, explanation: Dict[str, Any], 
                                  results: Dict[str, Any]) -> List[str]:
        """Grad-CAM ve SHAP sonuÃ§larÄ±nÄ± birleÅŸtirir."""
        insights = []
        
        # Grad-CAM insight'larÄ±
        if explanation["gradcam_explanation"].get("heatmap_generated"):
            insights.append("ğŸ¯ GÃ¶rsel analiz: Model gÃ¶z bÃ¶lgelerine odaklanmÄ±ÅŸ")
        
        # SHAP insight'larÄ±
        shap_data = explanation.get("shap_explanation", {})
        if "clinical_interpretation" in shap_data:
            insights.extend(shap_data["clinical_interpretation"][:3])  # Ä°lk 3 insight
        
        # Genel deÄŸerlendirme
        nys_detected = results.get("nystagmus_detected", False)
        strab_detected = results.get("strabismus_detected", False)
        
        if nys_detected and strab_detected:
            insights.append("âš ï¸ Ã‡oklu patoloji: Hem nistagmus hem ÅŸaÅŸÄ±lÄ±k tespit edildi")
        elif nys_detected:
            insights.append("ğŸ” Nistagmus odaklÄ± analiz: GÃ¶z hareketlerinde anormallik")
        elif strab_detected:
            insights.append("ğŸ“ ÅaÅŸÄ±lÄ±k odaklÄ± analiz: GÃ¶z hizalanmasÄ±nda sapma")
        else:
            insights.append("âœ… Normal analiz: Belirgin patoloji tespit edilmedi")
        
        return insights
    
    def _generate_clinical_conclusion(self, results: Dict[str, Any], 
                                    explanation: Dict[str, Any]) -> str:
        """Klinik sonuÃ§ oluÅŸturur."""
        nys_freq = results.get("nistagmus_frequency", 0.0)
        strab_angle = results.get("strabismus_angle", 0.0)
        
        conclusion = "KLÄ°NÄ°K DEÄERLENDÄ°RME:\n\n"
        
        if nys_freq > 3.0:
            conclusion += f"â€¢ Belirgin nistagmus bulgusu ({nys_freq:.2f} Hz) - Ä°leri deÄŸerlendirme gerekli\n"
        elif nys_freq > 1.5:
            conclusion += f"â€¢ Hafif nistagmus bulgusu ({nys_freq:.2f} Hz) - Takip Ã¶nerisi\n"
        else:
            conclusion += f"â€¢ Normal gÃ¶z hareketi ({nys_freq:.2f} Hz)\n"
        
        if strab_angle > 3.0:
            conclusion += f"â€¢ Belirgin ÅŸaÅŸÄ±lÄ±k ({strab_angle:.2f}Â°) - Oftalmolojik konsÃ¼ltasyon\n"
        elif strab_angle > 1.5:
            conclusion += f"â€¢ Hafif ÅŸaÅŸÄ±lÄ±k eÄŸilimi ({strab_angle:.2f}Â°) - Kontrol Ã¶nerisi\n"
        else:
            conclusion += f"â€¢ Normal gÃ¶z hizalanmasÄ± ({strab_angle:.2f}Â°)\n"
        
        # Model gÃ¼venilirliÄŸi
        detection_rate = results.get("face_detection_rate", 0.0)
        if detection_rate > 0.8:
            conclusion += f"\nâ€¢ Analiz kalitesi: YÃ¼ksek (%{detection_rate*100:.1f} tespit oranÄ±)"
        else:
            conclusion += f"\nâ€¢ Analiz kalitesi: Orta (%{detection_rate*100:.1f} tespit oranÄ±)"
        
        return conclusion

# Factory functions
def create_gradcam_explainer(model: nn.Module) -> GradCAMExplainer:
    """Grad-CAM explainer oluÅŸtur."""
    return GradCAMExplainer(model)

def create_shap_explainer(model_predict_fn) -> SHAPExplainer:
    """SHAP explainer oluÅŸtur."""
    return SHAPExplainer(model_predict_fn)

def create_combined_explainer(model: nn.Module, model_predict_fn = None) -> CombinedExplainer:
    """BirleÅŸik explainer oluÅŸtur."""
    return CombinedExplainer(model, model_predict_fn)

if __name__ == "__main__":
    # Test
    print("ğŸ”¬ GeliÅŸmiÅŸ aÃ§Ä±klanabilirlik sistemi test edildi")
    print("âœ… Grad-CAM support")
    print("âœ… SHAP support") 
    print("âœ… Combined explanation system")
    
    # Model wrapper Ã¶rneÄŸi
    def dummy_predict(features):
        """Dummy prediction function for testing."""
        return np.random.rand(len(features), 2)  # Binary classification
    
    # Test SHAP
    shap_explainer = SHAPExplainer(dummy_predict)
    test_features = {
        "nystagmus_frequency": 4.2,
        "movement_amplitude": 0.85,
        "regularity": 0.72,
        "strabismus_angle": 3.1,
        "strabismus_stability": 0.68
    }
    
    explanation = shap_explainer.explain_features(test_features)
    print(f"\nğŸ“Š SHAP aÃ§Ä±klama test: {explanation['method']}")
    print(f"ğŸ¯ Toplam etki: {explanation.get('total_effect', 'N/A')}") 